기온, 제품번호, 제품명, 성별, 키, 몸무게, 핏, 이미지링크, 구매사이즈, 사이즈+제품번호 


1. 데이터 설명 
기온 - 기온 데이터 
제품번호 - 제품을 구분하는 번호
제품명 - 제품의 이름
성별 - 사용자의 성별
키 - 사용자의 키
몸무게 - 사용자의 몸무게
핏 - 제품 핏 상태 ( 두가지로만 나뉘어있다는 오류.) 
이미지링크 - 제품 이미지 링크
구매사이즈 - 사용자가 구매한 제품의 사이즈 
사이즈+제품번호 - 사이즈의 제품 번호를 조합한 정보 

2. 데이터 전처리 
+ EDA 과정 넣기 
 이 결과에 따라서 피처 엔지니어링이 수정될 수 있음 
( 이미 무신사에서 가공되어진 데이터를 가져왔기 때문에 필요 없을듯?! )  

2.1 피처 엔지니어링 
 - 키와 몸무게를 숫자로 변환 ( cm, kg 제거해서 숫자만 남겨놓는다 ) 
 - 성별, 핏 one-hot encoding  ( 남자,여자 / 적당함, 큼, 작음 ) 

2.2 피처 선택 
 입력 피처 - 기온, 성별, 키, 몸무게, 핏 
 출력 피처 - 사이즈+제품번호 

3. 모델 선택 
 로지스틱 회귀
 기본적인 분류 알고리즘이기 때문에 데이터 관계가 선형이라고 예상될 때 기본 모델로 사용  하기 좋다. 특성의 가중치를 해석하기 용이해서 특성의 영향력을 알고 싶을 때 유용 
주의점 : 복잡한 비선형 관계나 상호작용 잘 포착 못할 수도 있다. 

 확률적 경사 하강법 ( SGD )  
 큰 데이터셋에서 빠른 학습이 필요할 때 사용. 계산 속도가 빨라서 대규모 데이터에 적합
 주의점 : 파라미터 튜닝이 중요 ! 학습률 등의 하이퍼 파라미터에 민감하게 반응할 수 있다.

 랜덤 포레스트
  모델의 크기가 크기 때문에 메모리 사용량이 크고 예측시간이 길 수 있다. 
 주의점 : 모델 크기가 커서 메모리 사용량이 크고 예측시간이 다소 길 수 있음

 엑스트라 트리 ( 랜덤 포레스트와 비슷, 부트스트랩 샘플 사용하지 않음)
 랜덤 포레스트와 비슷한 성능, 더 빠른 학습 시간
주의점 : 무작위성이 높아 모델 결과 일관성 떨어짐 

 Gradient Boosting ( 히스토그램 기반 그레이디언트 부스팅 ) 
 높은 성능을 원하고 데이터의 복잡한 패턴을 포착하려 할 때 사용 ( 히스토그램은 대규모 데이터셋에 빠르게 적용 )
주의점 : 오버피팅의 위험이 있어 교차 검증 및 하이퍼파라미터 튜닝이 중요 

4. 모델 학습 및 평가 
 4.1 데이터 분할 ( 훈련 세트, 테스트 세트) 
   1) 전체 데이터를 훈련 세트로 지정하는 경우 
      실제 성능 검증방법 없음. 과적합 위험 
      적용방법 : 실제 서비스에서 피드백이나 추가 데이터로 성능 평가 

   2) 기온별로 8:2 비율로 훈련,테스트 세트 분할하는 경우
       기온에 따라 제품 추천의 패턴이 다를 수 있어서 유용하다. 
       데이터가 불균형 할경우 어떤 기온대에서는 적은양의 데이터만 사용될 수 있음
       => 데이터가 약 100개씩 분류되어있어 불균형하진 않다 ! 
    
  4.2 모델 학습 , 평가 
   3. 모델 선택에 정리해둔 알고리즘을 각각 시도하여 성능을 확인한다. 
  테스트 데이터 사용해 모델 성능 평가. 

  4.3 하이퍼파라미터 
    모델 성능을 최적화하기 위해 하이퍼파라미터를 조절한다. 
    GridSearchCV, RandomizedSearchCV 를 사용해 최적의 하이퍼파라미터 찾는다. 
    랜덤 포레스트 주요 하이퍼파라미터 (엑스트라, 그레이디언트는 비슷함)
    :  max_depth: None (트리의 최대 깊이 제한 없음)
       min_samples_leaf: 4 (리프 노드가 되기 위한 최소 샘플 수)
       min_samples_split: 10 (내부 노드를 분할하기 위한 최소 샘플 수)
       n_estimators: 50 ,부스팅 단계의 수 (트리의 개수).
 
  4.4 앙상블 기법
   여러 개의 모델을 결합해 하나의 최종 모델을 만드는 것 
    배깅 : 동일한 모델 사용해 학습 데이터셋을 여러번 재샘플링 하여 여러 모델을 학습 시키고, 
   평균이나 투표를 통해 최종 결과 결정 => 랜덤 포레스트 
    부스팅 : 약한 학습기를 순차적으로 학습시키며 잘못 분류된 샘플에 더 많은 가중치 부여 
     => 그레이디언트 부스팅( XGBoost, LightGBM, CatBoost )
    스태킹 : 여러 다른 모델의 예측 결과를 기반으로 새로운 모델 학습 

  4.5 특성 중요도 및 선택 
    불필요한 특성 제거, 중요한 특성에 집중할 수 있음 
    랜덤  포레스트, 그레이디언트 부스팅 같은 트리기반 모델은 
    feature_importances_ 속성 통해 중요도 제공 !

 4.6 최종 모델 선택 및 배포 
    최적 모델 선택, 실제 환경에서 사용될 수 있도록 배포 



https://velog.io/@chaerin/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95



